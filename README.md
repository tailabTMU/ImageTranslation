# Generative Adversarial Networks for Neuroimage Translation

This code implements the CycleGAN and DCGAN models from "Generative Adversarial Networks for Neuroimage Translation" that was presented at PRHA 2023. These results were submitted to the Journal of Computational Biology. 

## Setup
All requirements that are needed to run the code can be found in the requirements.txt file. To run the code with GPU, ensure that the CUDA version is compatible with the libraries. 

To use this code with your own MRI images, you will need to create a nested folder, *data/MRI*, to store the images. In this experiment, the 3T and 1.5T images were stored as different file formats. The 3T images are identifiable by the .mha format and the 1.5T images are stored as .nii.gz. These images are stored as numpy arrays in the variable *images* for the 3T images and *images1* for the 1.5T scans. Ensure that you verify the size of your images during the preprocessing phase. Both field strength images were resized to (256, 256) for this experiment. 

## Running Experiments
After importing your images, you can run the following code(s) for each model:

### CycleGAN 
To train the CycleGAN model, run the script ```MRI_CycleGAN.py```.

### DCGAN
The DCGAN model is trained for the 3T and 1.5T image synthesis separately. As such, there is a provided code for each field strength.  

To train the DCGAN model for the 3T images, run the ```DCGAN_3T.py``` script.  
To train the DCGAN model for 1.5T, run the script ```DCGAN_15T.py```.

## Generating Results
After running the above experiments, the results will be saved in the following folders:  
* The generated models for the CycleGAN experiment can be found in the folder *models/CycleGAN*
* The DGCAN models, for both 3T and 1.5T, are found in the folder *models/DCGAN*
* The figures generated by the CycleGAN model are found in the folder *figures/CycleGAN*
* All generated figures from the DCGAN models are located in the folder *figures/DCGAN*
